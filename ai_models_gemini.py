"""
AI ëª¨ë¸ í†µí•© ì‹œìŠ¤í…œ - Gemini & Claude ì§€ì›
AI Models Integration System with Gemini & Claude Support
"""

import os
import json
import logging
from typing import Dict, List, Optional, Any
from datetime import datetime
import numpy as np
import pandas as pd
from dataclasses import dataclass

# AI/ML ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

try:
    from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
    from sklearn.model_selection import train_test_split
    from sklearn.preprocessing import StandardScaler
    from sklearn.metrics import mean_absolute_error, r2_score
    import joblib
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False


@dataclass
class PredictionResult:
    """ì˜ˆì¸¡ ê²°ê³¼"""
    predicted_price: float
    confidence_score: float
    price_range_min: float
    price_range_max: float
    factors: List[str]
    model_version: str


class UnifiedAIManager:
    """í†µí•© AI ê´€ë¦¬ì (Gemini & Claude)"""
    
    def __init__(self, prefer_gemini: bool = True):
        """
        Args:
            prefer_gemini: Trueë©´ ê¸°ë³¸ì ìœ¼ë¡œ Gemini ì‚¬ìš© (ë¹„ìš© íš¨ìœ¨ì )
        """
        self.prefer_gemini = prefer_gemini
        self.setup_logging()
        
        # Gemini ì´ˆê¸°í™”
        self.gemini_model = None
        self.gemini_available = False
        gemini_key = os.getenv('GEMINI_API_KEY')
        if gemini_key and GEMINI_AVAILABLE:
            try:
                genai.configure(api_key=gemini_key)
                self.gemini_model = genai.GenerativeModel('gemini-pro')
                self.gemini_available = True
                self.logger.info("âœ… Gemini AI initialized successfully")
            except Exception as e:
                self.logger.error(f"âŒ Failed to initialize Gemini AI: {e}")
        
        # Claude ì´ˆê¸°í™”
        self.claude_client = None
        self.claude_available = False
        claude_key = os.getenv('ANTHROPIC_API_KEY')
        if claude_key and ANTHROPIC_AVAILABLE:
            try:
                self.claude_client = anthropic.Anthropic(api_key=claude_key)
                self.claude_available = True
                self.logger.info("âœ… Claude AI initialized successfully")
            except Exception as e:
                self.logger.error(f"âŒ Failed to initialize Claude AI: {e}")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ AI í™•ì¸
        if not self.gemini_available and not self.claude_available:
            self.logger.warning("âš ï¸ No AI service available - using mock responses")
        
        # í™œì„± í”„ë¡œë°”ì´ë” ê²°ì •
        if prefer_gemini and self.gemini_available:
            self.active_provider = "gemini"
        elif self.claude_available:
            self.active_provider = "claude"
        elif self.gemini_available:
            self.active_provider = "gemini"
        else:
            self.active_provider = "mock"
        
        self.logger.info(f"ğŸ¯ Active AI Provider: {self.active_provider.upper()}")
    
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
    
    def analyze_land_with_ai(self, land_data: Dict, market_data: Dict = None, 
                            use_premium: bool = False) -> Dict:
        """
        AIë¥¼ í™œìš©í•œ í† ì§€ ë¶„ì„
        
        Args:
            land_data: í† ì§€ ì •ë³´
            market_data: ì‹œì¥ ë°ì´í„°
            use_premium: Trueë©´ Claude ì‚¬ìš© (ë” ì •í™•), Falseë©´ Gemini ìš°ì„ 
        """
        prompt = self._create_analysis_prompt(land_data, market_data)
        
        # í”„ë¦¬ë¯¸ì—„ ìš”ì²­ì´ê³  Claudeê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ Claude ì‚¬ìš©
        if use_premium and self.claude_available:
            return self._analyze_with_claude(prompt, land_data)
        
        # ê¸°ë³¸ì ìœ¼ë¡œ Gemini ì‚¬ìš© (ë¹„ìš© íš¨ìœ¨ì )
        if self.gemini_available:
            return self._analyze_with_gemini(prompt, land_data)
        
        # Geminiê°€ ì—†ìœ¼ë©´ Claude ì‚¬ìš©
        if self.claude_available:
            return self._analyze_with_claude(prompt, land_data)
        
        # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ëª¨ì˜ ì‘ë‹µ
        return self._get_mock_ai_analysis(land_data)
    
    def _analyze_with_gemini(self, prompt: str, land_data: Dict) -> Dict:
        """Geminië¡œ ë¶„ì„"""
        try:
            response = self.gemini_model.generate_content(prompt)
            ai_response = response.text
            self.logger.info("âœ… Gemini analysis completed")
            return self._parse_ai_response(ai_response)
        except Exception as e:
            self.logger.error(f"âŒ Gemini analysis failed: {e}")
            return self._get_mock_ai_analysis(land_data)
    
    def _analyze_with_claude(self, prompt: str, land_data: Dict) -> Dict:
        """Claudeë¡œ ë¶„ì„"""
        try:
            response = self.claude_client.messages.create(
                model="claude-3-sonnet-20240229",
                max_tokens=2000,
                temperature=0.3,
                messages=[{"role": "user", "content": prompt}]
            )
            ai_response = response.content[0].text
            self.logger.info("âœ… Claude analysis completed")
            return self._parse_ai_response(ai_response)
        except Exception as e:
            self.logger.error(f"âŒ Claude analysis failed: {e}")
            return self._get_mock_ai_analysis(land_data)
    
    def chat_consultation(self, user_message: str, context: Dict = None, 
                         use_premium: bool = False) -> str:
        """
        AI ìƒë‹´ ì±„íŒ…
        
        Args:
            user_message: ì‚¬ìš©ì ì§ˆë¬¸
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸
            use_premium: Trueë©´ Claude ì‚¬ìš©, Falseë©´ Gemini ìš°ì„ 
        """
        system_prompt = """ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ í† ì§€ ì „ë¬¸ ë¶€ë™ì‚° ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì „ë¬¸ ë¶„ì•¼:
- ë†ì§€, ì„ì•¼, ëŒ€ì§€ ë“± ëª¨ë“  ì§€ëª©ì˜ í† ì§€ ê±°ë˜
- ê°œë°œí–‰ìœ„í—ˆê°€, ìš©ë„ë³€ê²½, ë†ì§€ì „ìš©, ì‚°ì§€ì „ìš©
- í† ì§€ íˆ¬ì ì „ëµ ë° ë¦¬ìŠ¤í¬ ê´€ë¦¬
- ë¶€ë™ì‚° ê´€ë ¨ ì„¸ê¸ˆ ìƒë‹´

ìƒë‹´ ì›ì¹™:
1. ì •í™•í•˜ê³  ì‹¤ë¬´ì ì¸ ì¡°ì–¸ ì œê³µ
2. ë¦¬ìŠ¤í¬ë¥¼ ëª…í™•íˆ ê³ ì§€
3. ë²•ë¥  ì¤€ìˆ˜ ê°•ì¡°
4. ê³ ê° ë§ì¶¤í˜• ìƒë‹´
5. ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª…

í•œêµ­ì–´ë¡œ ì „ë¬¸ì ì´ë©´ì„œë„ ì¹œê·¼í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

        full_prompt = f"{system_prompt}\n\nì‚¬ìš©ì ì§ˆë¬¸: {user_message}"
        
        # í”„ë¦¬ë¯¸ì—„ ìš”ì²­ì´ê³  Claudeê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ Claude ì‚¬ìš©
        if use_premium and self.claude_available:
            return self._chat_with_claude(full_prompt, system_prompt, user_message)
        
        # ê¸°ë³¸ì ìœ¼ë¡œ Gemini ì‚¬ìš©
        if self.gemini_available:
            return self._chat_with_gemini(full_prompt)
        
        # Geminiê°€ ì—†ìœ¼ë©´ Claude ì‚¬ìš©
        if self.claude_available:
            return self._chat_with_claude(full_prompt, system_prompt, user_message)
        
        # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ëª¨ì˜ ì‘ë‹µ
        return self._get_mock_chat_response(user_message)
    
    def _chat_with_gemini(self, prompt: str) -> str:
        """Geminië¡œ ì±„íŒ…"""
        try:
            response = self.gemini_model.generate_content(prompt)
            return response.text
        except Exception as e:
            self.logger.error(f"âŒ Gemini chat failed: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    def _chat_with_claude(self, full_prompt: str, system_prompt: str, user_message: str) -> str:
        """Claudeë¡œ ì±„íŒ…"""
        try:
            response = self.claude_client.messages.create(
                model="claude-3-sonnet-20240229",
                max_tokens=1500,
                temperature=0.7,
                system=system_prompt,
                messages=[{"role": "user", "content": user_message}]
            )
            return response.content[0].text
        except Exception as e:
            self.logger.error(f"âŒ Claude chat failed: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    def analyze_contract(self, contract_text: str, use_premium: bool = False) -> Dict:
        """
        ê³„ì•½ì„œ ë¶„ì„
        
        Args:
            contract_text: ê³„ì•½ì„œ ë‚´ìš©
            use_premium: Trueë©´ Claude ì‚¬ìš© (ë” ì •í™•)
        """
        prompt = f"""ë‹¤ìŒ ë¶€ë™ì‚° ê³„ì•½ì„œë¥¼ ë¶„ì„í•˜ì—¬ ì£¼ìš” ì¡°í•­ê³¼ ë¦¬ìŠ¤í¬ë¥¼ ì‹ë³„í•´ì£¼ì„¸ìš”:

ê³„ì•½ì„œ ë‚´ìš©:
{contract_text}

ë¶„ì„ í•­ëª©:
1. ì£¼ìš” ì¡°í•­ í™•ì¸ (ë§¤ë§¤ê°€ê²©, ì”ê¸ˆì¼, íŠ¹ì•½ì‚¬í•­ ë“±)
2. ìœ„í—˜ ìš”ì†Œ ì‹ë³„
3. ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•œ ì‚¬í•­
4. ì¢…í•© ì˜ê²¬

JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

        # í”„ë¦¬ë¯¸ì—„ ìš”ì²­ì´ê³  Claudeê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ Claude ì‚¬ìš©
        if use_premium and self.claude_available:
            return self._analyze_contract_with_claude(prompt)
        
        # ê¸°ë³¸ì ìœ¼ë¡œ Gemini ì‚¬ìš©
        if self.gemini_available:
            return self._analyze_contract_with_gemini(prompt)
        
        # Geminiê°€ ì—†ìœ¼ë©´ Claude ì‚¬ìš©
        if self.claude_available:
            return self._analyze_contract_with_claude(prompt)
        
        # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ëª¨ì˜ ì‘ë‹µ
        return self._get_mock_contract_analysis()
    
    def _analyze_contract_with_gemini(self, prompt: str) -> Dict:
        """Geminië¡œ ê³„ì•½ì„œ ë¶„ì„"""
        try:
            response = self.gemini_model.generate_content(prompt)
            try:
                return json.loads(response.text)
            except json.JSONDecodeError:
                return self._structure_contract_response(response.text)
        except Exception as e:
            self.logger.error(f"âŒ Gemini contract analysis failed: {e}")
            return self._get_mock_contract_analysis()
    
    def _analyze_contract_with_claude(self, prompt: str) -> Dict:
        """Claudeë¡œ ê³„ì•½ì„œ ë¶„ì„"""
        try:
            response = self.claude_client.messages.create(
                model="claude-3-sonnet-20240229",
                max_tokens=2000,
                temperature=0.3,
                messages=[{"role": "user", "content": prompt}]
            )
            try:
                return json.loads(response.content[0].text)
            except json.JSONDecodeError:
                return self._structure_contract_response(response.content[0].text)
        except Exception as e:
            self.logger.error(f"âŒ Claude contract analysis failed: {e}")
            return self._get_mock_contract_analysis()
    
    def _create_analysis_prompt(self, land_data: Dict, market_data: Dict = None) -> str:
        """ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        prompt = f"""í† ì§€ ì „ë¬¸ê°€ë¡œì„œ ë‹¤ìŒ í† ì§€ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:

í† ì§€ ì •ë³´:
- ì£¼ì†Œ: {land_data.get('address', '')}
- ì§€ëª©: {land_data.get('land_category', '')}
- ë©´ì : {land_data.get('area', 0)}ã¡
- ê³µì‹œì§€ê°€: {land_data.get('official_price', 0):,}ì›/ã¡
- ìš©ë„ì§€ì—­: {land_data.get('zone_type', '')}

ë¶„ì„ ìš”ì²­ì‚¬í•­:
1. ê°œë°œ ê°€ëŠ¥ì„± í‰ê°€ (ì ìˆ˜ì™€ ë“±ê¸‰)
2. íˆ¬ì ë¦¬ìŠ¤í¬ ë¶„ì„
3. ì˜ˆìƒ ì‹œì¥ê°€ê²© ë²”ìœ„
4. íˆ¬ì ì¶”ì²œë„

JSON í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”."""
        
        if market_data:
            prompt += f"\n\nì‹œì¥ ë°ì´í„°:\n{json.dumps(market_data, ensure_ascii=False, indent=2)}"
        
        return prompt
    
    def _parse_ai_response(self, response: str) -> Dict:
        """AI ì‘ë‹µ íŒŒì‹±"""
        try:
            # JSON ì¶”ì¶œ ì‹œë„
            json_start = response.find('{')
            json_end = response.rfind('}') + 1
            if json_start >= 0 and json_end > json_start:
                json_str = response[json_start:json_end]
                return json.loads(json_str)
        except:
            pass
        
        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ êµ¬ì¡° ë°˜í™˜
        return {
            "ê°œë°œê°€ëŠ¥ì„±": {"ì ìˆ˜": 75, "ë“±ê¸‰": "B"},
            "ë¦¬ìŠ¤í¬": ["í˜„ì¥ í™•ì¸ í•„ìš”"],
            "ì˜ˆìƒê°€ê²©": {"ìµœì†Œ": 0, "ìµœëŒ€": 0},
            "ì¶”ì²œë„": "ë³´í†µ",
            "ai_response": response
        }
    
    def _structure_contract_response(self, response: str) -> Dict:
        """ê³„ì•½ì„œ ì‘ë‹µ êµ¬ì¡°í™”"""
        return {
            "ì£¼ìš”ì¡°í•­_í™•ì¸": [
                {"í•­ëª©": "ë§¤ë§¤ê°€ê²©", "í™•ì¸": "âœ“", "ì£¼ì˜ì‚¬í•­": "ì‹œì„¸ ëŒ€ë¹„ ì ì •ì„± í™•ì¸ í•„ìš”"}
            ],
            "ìœ„í—˜ìš”ì†Œ": ["ê³„ì•½ì„œ ì „ë¬¸ ê²€í†  ê¶Œì¥"],
            "ì¶”ê°€í™•ì¸ì‚¬í•­": ["ë²•ë¬´ì‚¬ ê²€í†  í•„ìš”"],
            "ì¢…í•©ì˜ê²¬": response[:500] + "..." if len(response) > 500 else response
        }
    
    def _get_mock_ai_analysis(self, land_data: Dict) -> Dict:
        """ëª¨ì˜ AI ë¶„ì„ ê²°ê³¼"""
        return {
            "ê°œë°œê°€ëŠ¥ì„±": {
                "ì ìˆ˜": 78,
                "ë“±ê¸‰": "B+",
                "ì£¼ìš”ìš”ì¸": ["êµí†µ ì ‘ê·¼ì„± ì–‘í˜¸", "ìš©ë„ì§€ì—­ ì í•©"]
            },
            "ë¦¬ìŠ¤í¬ë¶„ì„": [
                {"ìœ í˜•": "ë²•ì  ë¦¬ìŠ¤í¬", "ìˆ˜ì¤€": "ë‚®ìŒ", "ì„¤ëª…": "ì¼ë°˜ì ì¸ ê°œë°œ ì ˆì°¨ í•„ìš”"},
                {"ìœ í˜•": "ì‹œì¥ ë¦¬ìŠ¤í¬", "ìˆ˜ì¤€": "ë³´í†µ", "ì„¤ëª…": "ì‹œì¥ ë³€ë™ì„± ê³ ë ¤ í•„ìš”"}
            ],
            "ì˜ˆìƒê°€ê²©": {
                "ìµœì†Œ": land_data.get('official_price', 0) * 1.8,
                "ìµœëŒ€": land_data.get('official_price', 0) * 2.5,
                "ì¶”ì •": land_data.get('official_price', 0) * 2.1
            },
            "íˆ¬ìì¶”ì²œ": "ë³´í†µ - ì•ˆì •ì  íˆ¬ìì²˜"
        }
    
    def _get_mock_chat_response(self, user_message: str) -> str:
        """ëª¨ì˜ ì±„íŒ… ì‘ë‹µ"""
        responses = {
            "ë†ì§€": "ë†ì§€ íˆ¬ìëŠ” ë†ì§€ë²•ì— ë”°ë¥¸ ì œì•½ì´ ìˆìŠµë‹ˆë‹¤. ë†ì§€ì „ìš© ê°€ëŠ¥ì„±ì„ ë¨¼ì € í™•ì¸í•˜ì‹œê³ , ì „ìš©ë¶€ë‹´ê¸ˆë„ ê³ ë ¤í•˜ì…”ì•¼ í•©ë‹ˆë‹¤.",
            "ì„ì•¼": "ì„ì•¼ëŠ” ì‚°ì§€ê´€ë¦¬ë²•ì˜ ì ìš©ì„ ë°›ìŠµë‹ˆë‹¤. ì‚°ì§€ì „ìš©í—ˆê°€ ê°€ëŠ¥ ì—¬ë¶€ì™€ ê²½ì‚¬ë„, ì ‘ë„ ì¡°ê±´ì„ ê¼¼ê¼¼íˆ í™•ì¸í•˜ì„¸ìš”.",
            "ì„¸ê¸ˆ": "í† ì§€ ì·¨ë“ ì‹œ ì·¨ë“ì„¸ê°€ ë¶€ê³¼ë˜ë©°, ë³´ìœ  ì‹œ ì¬ì‚°ì„¸, ë§¤ê° ì‹œ ì–‘ë„ì†Œë“ì„¸ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì„¸ë¬´ì‚¬ ìƒë‹´ì„ ê¶Œí•©ë‹ˆë‹¤.",
            "ë§¹ì§€": "ë§¹ì§€ëŠ” ë„ë¡œì— ì ‘í•˜ì§€ ì•Šì€ í† ì§€ë¡œ, í†µí–‰ê¶Œ í™•ë³´ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤. ì£¼ë³€ í† ì§€ ì†Œìœ ìì™€ì˜ í˜‘ì˜ë‚˜ ë²•ì  ì ˆì°¨ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        }
        
        for keyword, response in responses.items():
            if keyword in user_message:
                return response
        
        return "í† ì§€ íˆ¬ìëŠ” ë‹¤ì–‘í•œ ìš”ì†Œë¥¼ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤. êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    
    def _get_mock_contract_analysis(self) -> Dict:
        """ëª¨ì˜ ê³„ì•½ì„œ ë¶„ì„"""
        return {
            "ì£¼ìš”ì¡°í•­_í™•ì¸": [
                {"í•­ëª©": "ë§¤ë§¤ê°€ê²©", "í™•ì¸": "âœ“", "ì£¼ì˜ì‚¬í•­": "ì‹œì„¸ ëŒ€ë¹„ ì ì •ì„± í™•ì¸"},
                {"í•­ëª©": "ì”ê¸ˆì¼", "í™•ì¸": "âœ“", "ì£¼ì˜ì‚¬í•­": "ëŒ€ì¶œ ìŠ¹ì¸ ê¸°ê°„ ê³ ë ¤"},
                {"í•­ëª©": "íŠ¹ì•½ì‚¬í•­", "í™•ì¸": "â–³", "ì£¼ì˜ì‚¬í•­": "ì„¸ë¶€ ì¡°ê±´ ëª…í™•í™” í•„ìš”"}
            ],
            "ìœ„í—˜ìš”ì†Œ": [
                "í† ì§€ì´ìš©ê³„íš ë³€ê²½ ê°€ëŠ¥ì„±",
                "ê°œë°œí–‰ìœ„í—ˆê°€ ì·¨ë“ ë¶ˆí™•ì‹¤ì„±",
                "ì ‘ë„ ì¡°ê±´ ë¯¸í™•ì¸"
            ],
            "ì¶”ê°€í™•ì¸ì‚¬í•­": [
                "í† ì§€ì´ìš©ê³„íší™•ì¸ì› ë°œê¸‰",
                "ì§€ì ë„ ë° ì¸¡ëŸ‰ ê²°ê³¼ í™•ì¸",
                "ì£¼ë³€ ê°œë°œ ê³„íš ì¡°ì‚¬"
            ],
            "ì¢…í•©ì˜ê²¬": "ì „ë°˜ì ìœ¼ë¡œ í‘œì¤€ì ì¸ ê³„ì•½ì„œì´ë‚˜, í† ì§€ íŠ¹ì„±ìƒ ê°œë°œ ê´€ë ¨ ì¡°ê±´ì„ ë” ëª…í™•íˆ í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤."
        }
    
    def get_provider_info(self) -> Dict:
        """í˜„ì¬ AI í”„ë¡œë°”ì´ë” ì •ë³´"""
        return {
            "active_provider": self.active_provider,
            "gemini_available": self.gemini_available,
            "claude_available": self.claude_available,
            "prefer_gemini": self.prefer_gemini
        }


# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
ClaudeAIManager = UnifiedAIManager
AIManager = UnifiedAIManager


class LandPricePredictor:
    """í† ì§€ ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸"""
    
    def __init__(self):
        self.model = None
        self.scaler = StandardScaler()
        self.is_trained = False
        self.setup_logging()
        
        if SKLEARN_AVAILABLE:
            self.model = GradientBoostingRegressor(
                n_estimators=100,
                learning_rate=0.1,
                max_depth=6,
                random_state=42
            )
        else:
            self.logger.warning("Scikit-learn not available - using simple prediction")
    
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
    
    def prepare_features(self, land_data: Dict, market_data: Dict = None) -> np.ndarray:
        """íŠ¹ì„± ì¤€ë¹„"""
        features = []
        
        # ê¸°ë³¸ íŠ¹ì„±
        features.extend([
            land_data.get('area', 0),
            land_data.get('official_price', 0),
            land_data.get('nearest_station_km', 5.0),
            1 if land_data.get('road_contact', False) else 0
        ])
        
        # ìš©ë„ì§€ì—­ ì¸ì½”ë”©
        zone_encoding = {
            'ì œ1ì¢…ì „ìš©ì£¼ê±°ì§€ì—­': 1, 'ì œ2ì¢…ì „ìš©ì£¼ê±°ì§€ì—­': 2,
            'ì œ1ì¢…ì¼ë°˜ì£¼ê±°ì§€ì—­': 3, 'ì œ2ì¢…ì¼ë°˜ì£¼ê±°ì§€ì—­': 4, 'ì œ3ì¢…ì¼ë°˜ì£¼ê±°ì§€ì—­': 5,
            'ì¤€ì£¼ê±°ì§€ì—­': 6, 'ì¤‘ì‹¬ìƒì—…ì§€ì—­': 10, 'ì¼ë°˜ìƒì—…ì§€ì—­': 9, 'ê·¼ë¦°ìƒì—…ì§€ì—­': 8,
            'ì¼ë°˜ê³µì—…ì§€ì—­': 7, 'ì¤€ê³µì—…ì§€ì—­': 7, 'ìì—°ë…¹ì§€ì§€ì—­': 2
        }
        features.append(zone_encoding.get(land_data.get('zone_type', ''), 3))
        
        # ì§€ëª© ì¸ì½”ë”©
        category_encoding = {
            'ëŒ€ì§€': 5, 'ì „': 3, 'ë‹µ': 3, 'ê³¼ìˆ˜ì›': 4, 'ì„ì•¼': 2,
            'ëª©ì¥ìš©ì§€': 3, 'ê³µì¥ìš©ì§€': 6, 'í•™êµìš©ì§€': 4
        }
        features.append(category_encoding.get(land_data.get('land_category', ''), 3))
        
        return np.array(features).reshape(1, -1)
    
    def predict_price(self, land_data: Dict, market_data: Dict = None) -> PredictionResult:
        """ê°€ê²© ì˜ˆì¸¡"""
        if not self.is_trained or not SKLEARN_AVAILABLE:
            return self._simple_price_prediction(land_data)
        
        features = self.prepare_features(land_data, market_data)
        features_scaled = self.scaler.transform(features)
        
        # ì˜ˆì¸¡
        predicted_price = self.model.predict(features_scaled)[0]
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence = min(0.95, max(0.6, self._calculate_confidence(land_data)))
        
        # ê°€ê²© ë²”ìœ„ ê³„ì‚°
        margin = predicted_price * (1 - confidence) * 0.5
        price_min = predicted_price - margin
        price_max = predicted_price + margin
        
        return PredictionResult(
            predicted_price=predicted_price,
            confidence_score=confidence,
            price_range_min=price_min,
            price_range_max=price_max,
            factors=self._get_prediction_factors(land_data),
            model_version="v1.0"
        )
    
    def _simple_price_prediction(self, land_data: Dict) -> PredictionResult:
        """ê°„ë‹¨í•œ ê°€ê²© ì˜ˆì¸¡"""
        official_price = land_data.get('official_price', 0)
        area = land_data.get('area', 0)
        
        # ê³µì‹œì§€ê°€ ê¸°ë°˜ ì¶”ì •
        multiplier = 2.0
        
        # ìš©ë„ì§€ì—­ë³„ ì¡°ì •
        zone_multipliers = {
            'ì¤‘ì‹¬ìƒì—…ì§€ì—­': 3.5, 'ì¼ë°˜ìƒì—…ì§€ì—­': 3.0, 'ê·¼ë¦°ìƒì—…ì§€ì—­': 2.8,
            'ì¤€ì£¼ê±°ì§€ì—­': 2.5, 'ì œ3ì¢…ì¼ë°˜ì£¼ê±°ì§€ì—­': 2.3, 'ì œ2ì¢…ì¼ë°˜ì£¼ê±°ì§€ì—­': 2.1,
            'ì œ1ì¢…ì¼ë°˜ì£¼ê±°ì§€ì—­': 1.9, 'ì œ2ì¢…ì „ìš©ì£¼ê±°ì§€ì—­': 1.8, 'ì œ1ì¢…ì „ìš©ì£¼ê±°ì§€ì—­': 1.7
        }
        
        zone_type = land_data.get('zone_type', '')
        multiplier = zone_multipliers.get(zone_type, multiplier)
        
        # ì ‘ë„ ì¡°ê±´ ì¡°ì •
        if not land_data.get('road_contact', True):
            multiplier *= 0.7
        
        # ì—­ì„¸ê¶Œ ì¡°ì •
        station_km = land_data.get('nearest_station_km', 5.0)
        if station_km <= 0.5:
            multiplier *= 1.3
        elif station_km <= 1.0:
            multiplier *= 1.2
        elif station_km <= 2.0:
            multiplier *= 1.1
        
        predicted_price = official_price * area * multiplier
        
        return PredictionResult(
            predicted_price=predicted_price,
            confidence_score=0.75,
            price_range_min=predicted_price * 0.85,
            price_range_max=predicted_price * 1.15,
            factors=[
                f"ê³µì‹œì§€ê°€ ê¸°ì¤€ {multiplier:.1f}ë°° ì ìš©",
                f"ìš©ë„ì§€ì—­: {zone_type}",
                f"ì—­ì„¸ê¶Œ: {station_km}km"
            ],
            model_version="simple_v1.0"
        )
    
    def _calculate_confidence(self, land_data: Dict) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚°"""
        confidence = 0.8
        required_fields = ['address', 'area', 'official_price', 'zone_type']
        completeness = sum(1 for field in required_fields if land_data.get(field)) / len(required_fields)
        confidence *= completeness
        return confidence
    
    def _get_prediction_factors(self, land_data: Dict) -> List[str]:
        """ì˜ˆì¸¡ ìš”ì¸ ì„¤ëª…"""
        factors = []
        
        if land_data.get('road_contact'):
            factors.append("ë„ë¡œ ì ‘í•¨ - ì ‘ê·¼ì„± ì–‘í˜¸")
        else:
            factors.append("ë§¹ì§€ - ì ‘ê·¼ì„± ì œì•½")
        
        station_km = land_data.get('nearest_station_km', 5.0)
        if station_km <= 1.0:
            factors.append("ì—­ì„¸ê¶Œ - êµí†µ í¸ë¦¬")
        
        zone_type = land_data.get('zone_type', '')
        if 'ìƒì—…' in zone_type:
            factors.append("ìƒì—…ì§€ì—­ - ê°œë°œ ê°€ì¹˜ ë†’ìŒ")
        elif 'ì£¼ê±°' in zone_type:
            factors.append("ì£¼ê±°ì§€ì—­ - ì•ˆì •ì  ìˆ˜ìš”")
        
        return factors
